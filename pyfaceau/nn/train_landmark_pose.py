"""
Training script for UnifiedLandmarkPoseNet

Trains a neural network to predict:
- 68 facial landmarks (2D coordinates)
- 6 global pose parameters [scale, rx, ry, rz, tx, ty]
- 34 local PDM shape parameters

Uses HDF5 training data generated by TrainingDataGenerator.

Usage:
    python train_landmark_pose.py --data training_data.h5 --output models/landmark_pose

    # Resume training
    python train_landmark_pose.py --data training_data.h5 --resume models/landmark_pose/checkpoint_best.pt
"""

import argparse
import json
import time
from pathlib import Path
from typing import Dict, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split

from .landmark_pose_net import UnifiedLandmarkPoseNet, LandmarkPoseLoss

# Add parent path for data module
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))
from data.hdf5_dataset import PyTorchTrainingDataset


class LandmarkPoseTrainer:
    """
    Trainer for UnifiedLandmarkPoseNet.

    Handles training loop, validation, checkpointing, and metrics tracking.
    """

    def __init__(
        self,
        model: UnifiedLandmarkPoseNet,
        train_loader: DataLoader,
        val_loader: DataLoader,
        device: torch.device,
        output_dir: Path,
        learning_rate: float = 1e-3,
        weight_decay: float = 1e-4,
        landmark_weight: float = 1.0,
        global_params_weight: float = 0.1,
        local_params_weight: float = 0.01,
    ):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # Loss function
        self.criterion = LandmarkPoseLoss(
            landmark_weight=landmark_weight,
            global_params_weight=global_params_weight,
            local_params_weight=local_params_weight,
        )

        # Optimizer
        self.optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay,
        )

        # Learning rate scheduler (cosine annealing with warm restarts)
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer,
            T_0=10,  # Restart every 10 epochs
            T_mult=2,  # Double period after each restart
            eta_min=1e-6,
        )

        # Tracking
        self.epoch = 0
        self.best_val_loss = float('inf')
        self.train_history = []
        self.val_history = []

    def train_epoch(self) -> Dict[str, float]:
        """Train for one epoch."""
        self.model.train()

        total_loss = 0.0
        total_lm_loss = 0.0
        total_gp_loss = 0.0
        total_lp_loss = 0.0
        num_batches = 0

        for batch in self.train_loader:
            # Move to device
            images = batch['image'].to(self.device)
            landmarks = batch['landmarks'].to(self.device)
            global_params = batch['global_params'].to(self.device)
            local_params = batch['local_params'].to(self.device)

            # Forward pass
            pred = self.model(images)

            # Compute loss
            target = {
                'landmarks': landmarks,
                'global_params': global_params,
                'local_params': local_params,
            }
            losses = self.criterion(pred, target)

            # Backward pass
            self.optimizer.zero_grad()
            losses['total'].backward()

            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

            self.optimizer.step()

            # Accumulate
            total_loss += losses['total'].item()
            total_lm_loss += losses['landmark'].item()
            total_gp_loss += losses['global_params'].item()
            total_lp_loss += losses['local_params'].item()
            num_batches += 1

        # Average losses
        metrics = {
            'loss': total_loss / num_batches,
            'landmark_loss': total_lm_loss / num_batches,
            'global_params_loss': total_gp_loss / num_batches,
            'local_params_loss': total_lp_loss / num_batches,
        }

        return metrics

    @torch.no_grad()
    def validate(self) -> Dict[str, float]:
        """Validate on validation set."""
        self.model.eval()

        total_loss = 0.0
        total_lm_loss = 0.0
        total_gp_loss = 0.0
        total_lp_loss = 0.0
        num_batches = 0

        # For correlation computation
        all_pred_lm = []
        all_target_lm = []

        for batch in self.val_loader:
            images = batch['image'].to(self.device)
            landmarks = batch['landmarks'].to(self.device)
            global_params = batch['global_params'].to(self.device)
            local_params = batch['local_params'].to(self.device)

            # Forward pass
            pred = self.model(images)

            # Compute loss
            target = {
                'landmarks': landmarks,
                'global_params': global_params,
                'local_params': local_params,
            }
            losses = self.criterion(pred, target)

            # Accumulate
            total_loss += losses['total'].item()
            total_lm_loss += losses['landmark'].item()
            total_gp_loss += losses['global_params'].item()
            total_lp_loss += losses['local_params'].item()
            num_batches += 1

            # Collect for correlation
            all_pred_lm.append(pred['landmarks'].cpu().numpy())
            all_target_lm.append(landmarks.cpu().numpy())

        # Compute metrics
        metrics = {
            'loss': total_loss / num_batches,
            'landmark_loss': total_lm_loss / num_batches,
            'global_params_loss': total_gp_loss / num_batches,
            'local_params_loss': total_lp_loss / num_batches,
        }

        # Compute landmark correlation
        pred_lm = np.concatenate(all_pred_lm, axis=0).reshape(-1)
        target_lm = np.concatenate(all_target_lm, axis=0).reshape(-1)
        correlation = np.corrcoef(pred_lm, target_lm)[0, 1]
        metrics['landmark_correlation'] = correlation

        # Compute mean absolute error for landmarks
        mae = np.abs(pred_lm - target_lm).mean()
        metrics['landmark_mae'] = mae

        return metrics

    def train(
        self,
        num_epochs: int,
        save_every: int = 5,
        early_stopping_patience: int = 20,
    ):
        """
        Full training loop.

        Args:
            num_epochs: Number of epochs to train
            save_every: Save checkpoint every N epochs
            early_stopping_patience: Stop if no improvement for N epochs
        """
        no_improvement_count = 0
        start_epoch = self.epoch

        print(f"\nStarting training from epoch {start_epoch + 1}")
        print(f"Training samples: {len(self.train_loader.dataset)}")
        print(f"Validation samples: {len(self.val_loader.dataset)}")
        print(f"Device: {self.device}")
        print("-" * 60)

        for epoch in range(start_epoch, start_epoch + num_epochs):
            self.epoch = epoch
            epoch_start = time.time()

            # Train
            train_metrics = self.train_epoch()
            self.train_history.append(train_metrics)

            # Validate
            val_metrics = self.validate()
            self.val_history.append(val_metrics)

            # Update scheduler
            self.scheduler.step()

            epoch_time = time.time() - epoch_start

            # Print progress
            print(
                f"Epoch {epoch + 1:3d} | "
                f"Train Loss: {train_metrics['loss']:.4f} | "
                f"Val Loss: {val_metrics['loss']:.4f} | "
                f"LM Corr: {val_metrics['landmark_correlation']:.4f} | "
                f"LM MAE: {val_metrics['landmark_mae']:.2f}px | "
                f"Time: {epoch_time:.1f}s"
            )

            # Check for improvement
            if val_metrics['loss'] < self.best_val_loss:
                self.best_val_loss = val_metrics['loss']
                self.save_checkpoint('checkpoint_best.pt')
                no_improvement_count = 0
                print(f"  -> New best model saved (val_loss: {self.best_val_loss:.4f})")
            else:
                no_improvement_count += 1

            # Save periodic checkpoint
            if (epoch + 1) % save_every == 0:
                self.save_checkpoint(f'checkpoint_epoch_{epoch + 1:03d}.pt')

            # Early stopping
            if no_improvement_count >= early_stopping_patience:
                print(f"\nEarly stopping triggered after {epoch + 1} epochs")
                break

        # Save final checkpoint
        self.save_checkpoint('checkpoint_final.pt')

        # Save training history
        self.save_history()

        print("\nTraining completed!")
        print(f"Best validation loss: {self.best_val_loss:.4f}")

    def save_checkpoint(self, filename: str):
        """Save model checkpoint."""
        checkpoint = {
            'epoch': self.epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'train_history': self.train_history,
            'val_history': self.val_history,
        }
        torch.save(checkpoint, self.output_dir / filename)

    def load_checkpoint(self, checkpoint_path: str):
        """Load model checkpoint."""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        self.epoch = checkpoint['epoch'] + 1  # Resume from next epoch
        self.best_val_loss = checkpoint['best_val_loss']
        self.train_history = checkpoint.get('train_history', [])
        self.val_history = checkpoint.get('val_history', [])

        print(f"Loaded checkpoint from epoch {checkpoint['epoch'] + 1}")
        print(f"Best validation loss so far: {self.best_val_loss:.4f}")

    def save_history(self):
        """Save training history to JSON."""
        history = {
            'train': self.train_history,
            'val': self.val_history,
            'best_val_loss': self.best_val_loss,
        }
        with open(self.output_dir / 'training_history.json', 'w') as f:
            json.dump(history, f, indent=2)


def create_data_loaders(
    h5_path: str,
    batch_size: int = 32,
    val_split: float = 0.1,
    num_workers: int = 4,
    seed: int = 42,
) -> Tuple[DataLoader, DataLoader]:
    """
    Create training and validation data loaders.

    Args:
        h5_path: Path to HDF5 training data
        batch_size: Batch size
        val_split: Fraction of data for validation
        num_workers: Number of data loading workers
        seed: Random seed for split

    Returns:
        Tuple of (train_loader, val_loader)
    """
    # Load dataset
    full_dataset = PyTorchTrainingDataset(h5_path, load_images=True, load_hog=False)

    # Split into train/val
    total_size = len(full_dataset)
    val_size = int(total_size * val_split)
    train_size = total_size - val_size

    generator = torch.Generator().manual_seed(seed)
    train_dataset, val_dataset = random_split(
        full_dataset,
        [train_size, val_size],
        generator=generator,
    )

    # Create loaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True,
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
    )

    return train_loader, val_loader


def main():
    parser = argparse.ArgumentParser(description='Train UnifiedLandmarkPoseNet')

    # Data
    parser.add_argument('--data', type=str, required=True,
                        help='Path to HDF5 training data')
    parser.add_argument('--output', type=str, default='models/landmark_pose',
                        help='Output directory for checkpoints')

    # Training
    parser.add_argument('--epochs', type=int, default=100,
                        help='Number of training epochs')
    parser.add_argument('--batch-size', type=int, default=32,
                        help='Batch size')
    parser.add_argument('--lr', type=float, default=1e-3,
                        help='Learning rate')
    parser.add_argument('--weight-decay', type=float, default=1e-4,
                        help='Weight decay')

    # Loss weights
    parser.add_argument('--lm-weight', type=float, default=1.0,
                        help='Landmark loss weight')
    parser.add_argument('--gp-weight', type=float, default=0.1,
                        help='Global params loss weight')
    parser.add_argument('--lp-weight', type=float, default=0.01,
                        help='Local params loss weight')

    # Model
    parser.add_argument('--width-mult', type=float, default=1.0,
                        help='MobileNetV2 width multiplier')

    # Resume
    parser.add_argument('--resume', type=str, default=None,
                        help='Path to checkpoint to resume from')

    # Other
    parser.add_argument('--val-split', type=float, default=0.1,
                        help='Validation split fraction')
    parser.add_argument('--num-workers', type=int, default=4,
                        help='Data loading workers')
    parser.add_argument('--seed', type=int, default=42,
                        help='Random seed')
    parser.add_argument('--save-every', type=int, default=10,
                        help='Save checkpoint every N epochs')
    parser.add_argument('--patience', type=int, default=30,
                        help='Early stopping patience')

    args = parser.parse_args()

    # Set random seeds
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)

    # Device
    if torch.backends.mps.is_available():
        device = torch.device('mps')  # Apple Silicon
    elif torch.cuda.is_available():
        device = torch.device('cuda')
    else:
        device = torch.device('cpu')

    print(f"Using device: {device}")

    # Create data loaders
    print(f"Loading data from: {args.data}")
    train_loader, val_loader = create_data_loaders(
        args.data,
        batch_size=args.batch_size,
        val_split=args.val_split,
        num_workers=args.num_workers,
        seed=args.seed,
    )

    # Create model
    model = UnifiedLandmarkPoseNet(width_mult=args.width_mult)
    num_params = sum(p.numel() for p in model.parameters())
    print(f"Model parameters: {num_params:,}")

    # Create trainer
    trainer = LandmarkPoseTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=device,
        output_dir=args.output,
        learning_rate=args.lr,
        weight_decay=args.weight_decay,
        landmark_weight=args.lm_weight,
        global_params_weight=args.gp_weight,
        local_params_weight=args.lp_weight,
    )

    # Resume if specified
    if args.resume:
        trainer.load_checkpoint(args.resume)

    # Train
    trainer.train(
        num_epochs=args.epochs,
        save_every=args.save_every,
        early_stopping_patience=args.patience,
    )

    # Export to ONNX and CoreML
    print("\nExporting trained model...")
    output_dir = Path(args.output)

    # Load best checkpoint
    best_checkpoint = torch.load(output_dir / 'checkpoint_best.pt', map_location='cpu')
    model.load_state_dict(best_checkpoint['model_state_dict'])
    model.eval()

    # Export ONNX
    from .landmark_pose_net import export_to_onnx, export_to_coreml

    onnx_path = output_dir / 'landmark_pose.onnx'
    export_to_onnx(model, str(onnx_path))

    # Export CoreML (if available)
    try:
        coreml_path = output_dir / 'landmark_pose.mlpackage'
        export_to_coreml(model, str(coreml_path))
    except ImportError:
        print("CoreML export skipped (coremltools not installed)")


if __name__ == '__main__':
    main()
